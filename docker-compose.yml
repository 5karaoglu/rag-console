version: '3.8'

services:
  rag-app:
    build: .
    stdin_open: true  # STDIN'i açık tut
    tty: true  # TTY ata
    volumes:
      - ./data/chroma_db:/app/chroma_db  # ChromaDB verilerini kalıcı hale getir
      - ./data/cache/huggingface:/app/cache/huggingface  # Hugging Face cache
      - ./data/cache/torch:/app/cache/torch  # PyTorch cache
      - ./data/cache/safetensors:/root/.cache/huggingface/hub  # Safetensors cache
      - ./data/cache/tokenizers:/root/.cache/huggingface/transformers  # Tokenizer cache
      - ${JSON_PATH:-./Book1.json}:/app/Book1.json  # JSON dosyasını bağla
    environment:
      - TRANSFORMERS_CACHE=/app/cache/huggingface
      - TORCH_HOME=/app/cache/torch
      - HF_HOME=/app/cache/huggingface
      - HUGGINGFACE_HUB_CACHE=/app/cache/huggingface
      - SENTENCE_TRANSFORMERS_HOME=/app/cache/huggingface
      - XDG_CACHE_HOME=/app/cache
      - HUGGING_FACE_TOKEN=${HUGGING_FACE_TOKEN}  # Hugging Face token'ı
      - USE_LOCAL_MODEL_FIRST=true  # Önce yerel model dene
      - PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:128,garbage_collection_threshold:0.8  # CUDA bellek ayarları
      - CUDA_VISIBLE_DEVICES=0,1  # Kullanılacak GPU'ları belirt
      - TOKENIZERS_PARALLELISM=true  # Tokenizer paralelleştirmeyi etkinleştir
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all  # Tüm GPU'ları kullan
              capabilities: [gpu]
    shm_size: 8gb  # Paylaşılan bellek boyutunu artır 