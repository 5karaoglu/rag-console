import pandas as pd
import chromadb
from chromadb.utils import embedding_functions
import typer
from rich.console import Console
from rich.prompt import Prompt
from transformers import AutoModelForCausalLM, AutoTokenizer
import torch
from pathlib import Path
import warnings
import traceback
import os
warnings.filterwarnings('ignore')

console = Console()
app = typer.Typer()

class RAGSystem:
    def __init__(self, excel_path: str):
        try:
            self.excel_path = excel_path
            self.device = "cuda" if torch.cuda.is_available() else "cpu"
            console.print(f"\nCihaz: {self.device}", style="yellow")
            
            # Hugging Face token kontrolÃ¼
            self.hf_token = os.getenv('HUGGING_FACE_TOKEN')
            if not self.hf_token:
                raise ValueError("HUGGING_FACE_TOKEN bulunamadÄ±! LÃ¼tfen .env dosyasÄ±na token'Ä±nÄ±zÄ± ekleyin.")
            
            self.setup_model()
            self.setup_database()
        except Exception as e:
            console.print("\nâŒ BaÅŸlatma HatasÄ±:", style="bold red")
            console.print(f"Hata MesajÄ±: {str(e)}", style="red")
            console.print("\nHata DetayÄ±:", style="bold red")
            console.print(traceback.format_exc(), style="red")
            raise e
        
    def setup_model(self):
        try:
            console.print("\nModel yÃ¼kleniyor...", style="yellow")
            console.print(f"Model: deepseek-ai/DeepSeek-R1-Distill-Qwen-32B", style="yellow")
            
            self.model_name = "deepseek-ai/DeepSeek-R1-Distill-Qwen-32B"
            
            # Tokenizer yapÄ±landÄ±rmasÄ±
            console.print("\nTokenizer yÃ¼kleniyor...", style="yellow")
            self.tokenizer = AutoTokenizer.from_pretrained(
                self.model_name,
                token=self.hf_token,
                trust_remote_code=True,
                padding_side="left",
                use_fast=False
            )
            console.print("Tokenizer yÃ¼klendi!", style="green")
            
            if self.tokenizer.pad_token is None:
                self.tokenizer.pad_token = self.tokenizer.eos_token
            
            # Model yapÄ±landÄ±rmasÄ±
            console.print("\nModel dosyalarÄ± indiriliyor...", style="yellow")
            self.model = AutoModelForCausalLM.from_pretrained(
                self.model_name,
                token=self.hf_token,
                torch_dtype=torch.bfloat16,
                device_map="auto",
                trust_remote_code=True,
                low_cpu_mem_usage=True,
                use_cache=True
            )
            console.print("Model yÃ¼klendi!", style="green")
            
            self.model.config.pad_token_id = self.tokenizer.pad_token_id
            console.print("\nModel yapÄ±landÄ±rmasÄ± tamamlandÄ±!", style="green")
            
        except Exception as e:
            console.print("\nâŒ Model YÃ¼kleme HatasÄ±:", style="bold red")
            console.print(f"Hata MesajÄ±: {str(e)}", style="red")
            console.print("\nHata DetayÄ±:", style="bold red")
            console.print(traceback.format_exc(), style="red")
            raise e
        
    def setup_database(self):
        console.print("VeritabanÄ± hazÄ±rlanÄ±yor...", style="yellow")
        self.chroma_client = chromadb.PersistentClient(path="./chroma_db")
        
        # Sentence transformer embedding fonksiyonunu kullan
        self.embedding_function = embedding_functions.SentenceTransformerEmbeddingFunction(
            model_name="all-MiniLM-L6-v2"
        )
        
        # Koleksiyon oluÅŸtur veya var olanÄ± al
        self.collection = self.chroma_client.get_or_create_collection(
            name="excel_data",
            embedding_function=self.embedding_function
        )
        
        # Excel verilerini yÃ¼kle ve veritabanÄ±na ekle
        if self.collection.count() == 0:
            self.load_excel_data()
            
        console.print("VeritabanÄ± hazÄ±r!", style="green")
        
    def load_excel_data(self):
        console.print("Excel verisi yÃ¼kleniyor...", style="yellow")
        df = pd.read_excel(self.excel_path)
        
        # Her satÄ±rÄ± bir dÃ¶kÃ¼man olarak ekle
        for idx, row in df.iterrows():
            # SatÄ±rdaki tÃ¼m deÄŸerleri stringe Ã§evir ve birleÅŸtir
            content = " ".join([f"{col}: {str(val)}" for col, val in row.items()])
            self.collection.add(
                documents=[content],
                ids=[f"row_{idx}"]
            )
        console.print("Excel verisi yÃ¼klendi!", style="green")
        
    def query(self, question: str) -> str:
        # Benzer dÃ¶kÃ¼manlarÄ± bul
        results = self.collection.query(
            query_texts=[question],
            n_results=3
        )
        
        # Prompt oluÅŸtur
        context = "\n".join(results["documents"][0])
        prompt = f"""AÅŸaÄŸÄ±daki baÄŸlam verilmiÅŸtir. Bu baÄŸlamÄ± kullanarak soruyu yanÄ±tla.

BaÄŸlam:
{context}

Soru: {question}

YanÄ±t:"""
        
        # Model ile yanÄ±t oluÅŸtur
        inputs = self.tokenizer(prompt, return_tensors="pt").to(self.device)
        outputs = self.model.generate(
            **inputs,
            max_length=512,
            num_return_sequences=1,
            temperature=0.7
        )
        response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)
        
        return response.split("YanÄ±t:")[-1].strip()

@app.command()
def main(excel_path: str = "Book1.xlsx"):
    """
    RAG sistemini baÅŸlat ve kullanÄ±cÄ± sorularÄ±nÄ± yanÄ±tla.
    """
    try:
        rag = RAGSystem(excel_path)
        console.print("\nğŸ¤– RAG Sistemi hazÄ±r! Ã‡Ä±kmak iÃ§in 'exit' yazÄ±n.\n", style="bold green")
        
        while True:
            question = Prompt.ask("\nSorunuzu yazÄ±n")
            
            if question.lower() == "exit":
                break
                
            with console.status("YanÄ±t oluÅŸturuluyor..."):
                response = rag.query(question)
                
            console.print("\nYanÄ±t:", style="bold blue")
            console.print(response, style="green")
            
    except Exception as e:
        console.print(f"\nâŒ Hata: {str(e)}", style="bold red")

if __name__ == "__main__":
    app() 